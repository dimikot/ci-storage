#!/usr/bin/python3 -u
from __future__ import annotations
import argparse
import collections
import dataclasses
import os.path
import re
import shlex
import subprocess
import sys
import tempfile
import textwrap
import time
import typing

STORAGE_MAX_AGE_SEC_DEFAULT = 3600 * 4
STORAGE_MAX_AGE_SEC_BAK = 60
STORAGE_DIR_DEFAULT = "~/ci-storage"
META_FILE = ".ci-storage.meta"
LOCAL_META_FILE_DIR = "/tmp" if os.access("/tmp", os.W_OK) else tempfile.gettempdir()
MAX_FULL_SNAPSHOT_HISTORY = 10


#
# Tool entry point.
#
def main():
    parser = argparse.ArgumentParser(
        description="""\
            Quickly stores the content of some local directory in the storage
            with the provided slot id on a remote host, or loads the content
            from the storage to that directory. The tool makes some smart
            differential optimizations along the way to operate as fast as
            possible (typically, 4 seconds for a 1.5G directory with 200K files
            in it on Linux EXT4).

            Under the hood, the tool uses rsync. When storing to the remote
            storage, it uses rsync's "--link-dest" mode pointing to the most
            recently created slot, to reuse as many existing files in the
            storage as possible (hoping that almost all files to be stored in
            the current slot are the same as the files in the recent slot, which
            is often times true for e.g. node_modules directories). If a slot
            with the same id already exists, it is overwritten in a
            transaction-safe fashion.

            When loading the files from a remote storage slot to a local
            directory, implies that the local directory already contains almost
            all files equal to the remote ones, so rsync can run efficiently.
        """,
        formatter_class=ParagraphFormatter,
    )
    parser.add_argument(
        "action",
        type=str,
        choices=["store", "load"],
        help="action to run",
    )
    parser.add_argument(
        "--storage-host",
        type=str,
        required=False,
        help="storage host in the format [user@]host[:port]; it must allow password-free SSH key based access; if omitted, uses the local filesystem (no SSH)",
    )
    parser.add_argument(
        "--storage-dir",
        type=str,
        default=STORAGE_DIR_DEFAULT,
        required=False,
        help=f"storage directory path on the storage host (will be created if it does not exist)",
    )
    parser.add_argument(
        "--storage-max-age-sec",
        type=str,
        default=str(STORAGE_MAX_AGE_SEC_DEFAULT),
        required=False,
        help="remove slots created earlier than this many seconds ago",
    )
    parser.add_argument(
        "--slot-id",
        type=str,
        required=True,
        default=[],
        action="append",
        help='id of the slot to store to or load from; use "*" to load a smart-random slot (e.g. most recent or best in terms of layer compatibility) and skip if it does not exist; when loading, you may provide multiple --slot-id options to try loading them in order',
    )
    parser.add_argument(
        "--local-dir",
        type=str,
        required=True,
        help="local directory path",
    )
    parser.add_argument(
        "--exclude",
        type=str,
        default=[],
        action="append",
        help="exclude pattern(s) for rsync",
    )
    parser.add_argument(
        "--layer",
        type=str,
        default=[],
        action="append",
        help="include pattern(s) for rsync; if set, only the matching files will be transferred; empty directories will be ignored; deletion will be turned off on load",
    )
    parser.add_argument(
        "--verbose",
        default=False,
        action="store_true",
        help="if set, prints the list of transferred files",
    )
    args = parser.parse_intermixed_args()

    action: typing.Literal["store", "load"] = args.action
    storage_host: str | None = args.storage_host or None
    storage_dir: str = (
        re.sub(r"/+$", "", args.storage_dir)
        if args.storage_dir
        else STORAGE_DIR_DEFAULT
    )
    storage_max_age_sec: int = int(
        args.storage_max_age_sec or str(STORAGE_MAX_AGE_SEC_DEFAULT)
    )
    slot_ids: list[str] = " ".join(args.slot_id).split()
    local_dir: str = re.sub(r"/+$", "", args.local_dir)
    exclude: list[str] = [
        line for line in "\n".join(args.exclude).splitlines() if line.strip()
    ]
    layer: list[str] = [
        line for line in "\n".join(args.layer).splitlines() if line.strip()
    ]
    verbose: bool = args.verbose

    if storage_host:
        # Rsync doesn't expand "~" in the remote path when syncing to a remote
        # host, but it is anyways relative to the remote user's home directory,
        # so we just remove "~".
        storage_dir = re.sub(r"^~/*", "", storage_dir) or "."
    else:
        # When syncing to the current filesystem, expand "~" manually, since
        # rsync doesn't do it.
        storage_dir = os.path.expanduser(storage_dir)

    if action == "store":
        if len(slot_ids) != 1:
            parser.error(f"for {action} action, exactly one --slot-id is required")
        action_store(
            storage_host=storage_host,
            storage_dir=storage_dir,
            slot_id=slot_ids[0],
            local_dir=local_dir,
            exclude=exclude,
            layer=layer,
            verbose=verbose,
        )
        action_maintenance(
            storage_host=storage_host,
            storage_dir=storage_dir,
            max_age_sec=storage_max_age_sec,
        )
    if action == "load":
        if not slot_ids:
            parser.error(f"for {action} action, at one or many --slot-id is required")
        action_load(
            storage_host=storage_host,
            storage_dir=storage_dir,
            slot_ids=slot_ids,
            local_dir=local_dir,
            exclude=exclude,
            layer=layer,
            verbose=verbose,
        )


#
# Loads the content from the storage to the local directory.
#
# Multiple slot ids may be passed; in this case, they are checked in order, and
# the 1st slot existing in the storage is loaded.
#
# One of the slot ids may be "*", which means that we need to load "some good
# enough" slot from the storage:
# - If we are loading a layer, then we try to use the slot id which "best
#   matches" the full (non-layer) snapshot loaded in the past.
# - If we are loading a full snapshot,
#
def action_load(
    *,
    storage_host: str | None,
    storage_dir: str,
    slot_ids: list[str],
    local_dir: str,
    exclude: list[str],
    layer: list[str],
    verbose: bool,
):
    full_snapshot_history = None
    if layer:
        meta = SlotMeta.read_from(local_dir=local_dir)
        full_snapshot_history = meta.full_snapshot_history

    slot_infos = list_slots(
        storage_host=storage_host,
        storage_dir=storage_dir,
    )

    slot_id = ""
    for id in map(normalize_slot_id, slot_ids):
        prefix = f'Checking slot-id="{id}"...'
        if id == "*":
            if not slot_infos:
                print(f"{prefix} storage has no slots, so exiting with a no-op")
                return
            elif full_snapshot_history is None:
                slot_id = list(slot_infos.keys())[0]
                print(
                    f'{prefix} using the most recent slot-id="{slot_id}" for the full (non-layer) load'
                )
                break
            elif len(full_snapshot_history) > 0:
                print(
                    f"{prefix} prioritizing slots from past full snapshot loading history..."
                )
                for id in full_snapshot_history:
                    prefix = f'Checking slot-id="{id}" from history...'
                    if id in slot_infos:
                        slot_id = id
                        print(f"{prefix} found in the storage, using it")
                        break
                    else:
                        print(f"{prefix} not found in the storage")
                if not slot_id:
                    slot_id = list(slot_infos.keys())[0]
                    print(
                        f'None slots from past full snapshot loading history were found in the storage, so using just the most recent slot-id="{slot_id}"'
                    )
                break
            else:
                slot_id = list(slot_infos.keys())[0]
                print(
                    f'{prefix} no past loading history, so using just the most recent slot-id="{slot_id}"'
                )
                break
        elif id in slot_infos:
            slot_id = id
            print(f"{prefix} found in the storage, using it")
            break
        else:
            print(f"{prefix} not found in the storage")

    if not slot_id:
        raise UserException(
            f"none of the provided slot id(s) were found in the storage, aborting"
        )

    host, port = parse_host_port(storage_host)
    check_call(
        cmd=[
            "rsync",
            *build_rsync_args(
                host=host,
                port=port,
                action="load",
                exclude=exclude,
                layer=layer,
                verbose=verbose,
            ),
            (f"{host}:" if host else "") + f"{storage_dir}/{slot_id}/",
            f"{local_dir}/",
        ],
        print_elapsed=True,
    )

    if not layer:
        slot_info = slot_infos[slot_id]
        slot_info.meta.full_snapshot_history.insert(0, slot_id)
        slot_info.meta.write_to(local_dir=local_dir)


#
# Stores the content of the local directory in the storage with the provided
# slot id on a remote host.
#
def action_store(
    *,
    storage_host: str | None,
    storage_dir: str,
    slot_id: str,
    local_dir: str,
    exclude: list[str],
    layer: list[str],
    verbose: bool,
):
    slot_id = normalize_slot_id(slot_id)
    if slot_id == "*":
        raise UserException(f'slot_id="{slot_id}" is not allowed for "store" action')

    meta = None
    if not layer:
        meta = SlotMeta.read_from(local_dir=local_dir)
        meta.full_snapshot_history.insert(0, slot_id)

    slot_infos = list_slots(
        storage_host=storage_host,
        storage_dir=storage_dir,
    )

    slot_recent = list(slot_infos.values())[0] if slot_infos else None
    slot_id_tmp = f"{slot_id}.tmp.{int(time.time())}"
    host, port = parse_host_port(storage_host)
    check_call(
        cmd=[
            "rsync",
            "--inplace",
            *([f"--link-dest=../{slot_recent.id}/"] if slot_recent else []),
            *build_rsync_args(
                host=host,
                port=port,
                action="store",
                exclude=exclude,
                layer=layer,
                verbose=verbose,
            ),
            f"{local_dir}/",
            (f"{host}:" if host else "") + f"{storage_dir}/{slot_id_tmp}/",
        ],
        print_elapsed=True,
    )

    print(
        check_output_script(
            host=storage_host,
            script=SCRIPTS["COMMIT_SLOT"],
            args=[
                storage_dir,
                slot_id_tmp,
                slot_id,
                meta.serialize() if meta else "",
            ],
            indent=True,
        ),
        end="",
    )

    if meta:
        meta.write_to(local_dir=local_dir)


#
# Runs the maintenance script for the storage.
#
def action_maintenance(
    *,
    storage_host: str | None,
    storage_dir: str,
    max_age_sec: int,
):
    print(
        check_output_script(
            host=storage_host,
            script=SCRIPTS["MAINTENANCE"],
            args=[storage_dir, str(max_age_sec)],
            indent=True,
        ),
        end="",
    )


#
# Returns the list of existing slot ids and their ages in seconds, sorted by age
# (i.e. most recently created slots on top of the list). Also, as a side effect,
# touches the newest slot directory on the server (assuming it'll be accessed),
# so it will unlikely be garbage collected anytime soon.
#
def list_slots(
    *,
    storage_host: str | None,
    storage_dir: str,
) -> collections.OrderedDict[str, SlotInfo]:
    slot_infos = collections.OrderedDict[str, SlotInfo]()
    lines = check_output_script(
        host=storage_host,
        script=SCRIPTS["LIST_SLOTS"],
        args=[storage_dir],
    )
    for line in lines.splitlines():
        match = re.match(r"^(\S+) (\d+) (.*)$", line)
        if match:
            slot_id = match.group(1)
            slot_infos[slot_id] = SlotInfo(
                id=slot_id,
                age=int(match.group(2)),
                meta=SlotMeta.deserialize(
                    match.group(3).encode().decode("unicode_escape")
                ),
            )
    return slot_infos


#
# Replaces all characters invalid in the file name with underscores.
#
def normalize_slot_id(
    slot_id: str,
) -> str:
    return re.sub(r"[^a-zA-Z0-9_-]", "_", slot_id) if slot_id != "*" else slot_id


#
# Runs an inline script and returns its output. If the call succeeded, but
# produced some stderr, prints it.
#
def check_output_script(
    *,
    host: str | None,
    script: str,
    args: list[str] = [],
    indent: bool = False,
) -> str:
    return check_output(host=host, cmd=["perl", "-we", script, *args], indent=indent)


#
# Runs a command and returns its output. If the call succeeded, but produced
# some stderr, prints it.
#
def check_output(
    *,
    host: str | None,
    cmd: list[str],
    indent: bool = False,
) -> str:
    host, port = parse_host_port(host)
    if host:
        ssh_prefix = [*build_ssh_cmd(port=port), host]
        print(f"$ {cmd_to_debug_str([*ssh_prefix, *cmd])}")
        cmd = [*ssh_prefix, shlex.join(cmd)]
    else:
        print(f"$ {cmd_to_debug_str(cmd)}")
    res = subprocess.run(
        cmd,
        text=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        check=True,
    )
    if res.stderr:
        print(textwrap.indent(res.stderr.rstrip(), "  "))
    return textwrap.indent(res.stdout, "  ") if indent else res.stdout


#
# Runs a command and passes through its output from both stdout and stderr as it
# arrives (without any buffering).
#
def check_call(
    *,
    cmd: list[str],
    print_elapsed: bool = False,
) -> None:
    print(f"$ {cmd_to_debug_str(cmd)}")
    start_time = time.time()
    with subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    ) as process:
        while process.stdout:
            line = process.stdout.readline()
            if not line and process.poll() is not None:
                break
            if line.strip():
                print(f"  {line}", end="")
        elapsed = f"  elapsed: {time.time() - start_time:.2f} sec"
        if process.returncode:
            raise subprocess.CalledProcessError(
                process.returncode,
                process.args,
                output="",
                stderr=elapsed,
            )
        elif print_elapsed:
            print(elapsed)


#
# Converts a command to a debug string.
#
def cmd_to_debug_str(
    cmd: list[str],
) -> str:
    inv = dict((v, k) for k, v in SCRIPTS.items())
    return shlex.join(
        [
            f"<{inv[arg]}>" if arg in inv else arg.rstrip().replace("\n", "\\n")
            for arg in cmd
        ]
    )


#
# Parses host:port pair (with port being optional).
#
def parse_host_port(
    host_port: str | None,
) -> tuple[str | None, int | None]:
    if not host_port:
        return None, None
    match = re.match(r"^(.*?)(?::(\d+))?$", host_port)
    if match and match.group(2):
        return match.group(1), int(match.group(2))
    else:
        return host_port, None


#
# Builds ssh command line.
#
def build_ssh_cmd(
    *,
    port: int | None,
) -> list[str]:
    return [
        "ssh",
        "-oStrictHostKeyChecking=no",
        "-oUserKnownHostsFile=/dev/null",
        "-oLogLevel=error",
        *([f"-p{port}"] if port else []),
    ]


#
# Builds some of rsync options.
#
def build_rsync_args(
    *,
    host: str | None,
    port: int | None,
    action: typing.Literal["store", "load"],
    exclude: list[str],
    layer: list[str],
    verbose: bool,
) -> list[str]:
    version_info = check_output(host=None, cmd=["rsync", "--version"])
    version_str = "unknown version"
    version_supports_nanoseconds = False
    match = re.search(r"version\s+([\d.]+)", version_info)
    if match:
        version_str = match.group(1)
        version = tuple(int(v) for v in version_str.split("."))
        version_supports_nanoseconds = version >= (3, 1, 0)
    print(
        f"  {version_str}: "
        + (
            "using nanosecond precision for timestamps"
            if version_supports_nanoseconds
            else "too old; doesn't support nanosecond precision for timestamps; only 1 second accuracy"
        )
    )
    return [
        *(["-e", shlex.join(build_ssh_cmd(port=port))] if host else []),
        "-a",
        "--partial",
        "--stats",
        "--human-readable",
        # Nanosecond precision for mtime comparison if supported. Notice that we
        # don't check the server-side version: if it's older, then we're doomed,
        # all files will be treated as changed likely.
        *(["--modify-window=-1"] if version_supports_nanoseconds else []),
        *([] if layer and action == "load" else ["--delete"]),
        *(["-vv"] if verbose and layer else ["-v"] if verbose else []),
        f"--exclude={META_FILE}",
        *[f"--exclude={pattern}" for pattern in exclude],
        *(
            [
                "--include=*/",
                *[f"--include={pattern}" for pattern in layer],
                "--exclude=*",
            ]
            if layer and layer != ["*"]
            else []
        ),
        *(["--prune-empty-dirs"] if layer and action == "store" else []),
    ]


#
# Returns unique elements of a list preserving the order.
#
def unique(arr: list[str]) -> list[str]:
    seen: set[str] = set()
    return [x for x in arr if not (x in seen or seen.add(x))]


#
# A helper class for ArgumentParser.
#
class ParagraphFormatter(argparse.HelpFormatter):
    def _fill_text(self, text: str, width: int, indent: str) -> str:
        return "\n\n".join(
            [
                textwrap.indent(textwrap.fill(paragraph, width), indent)
                for paragraph in textwrap.dedent(text).split("\n\n")
            ]
        )


#
# A meta information about some particular full (non-layer) slot. Can serialize
# and deserialize itself to/from a string using an env-like format.
#
# On local machine, the meta file is stored in LOCAL_META_FILE_DIR (which is
# typically "/tmp"), and the name of that file is suffixes with some hash
# derivative of local_dir. This allows to not pollute local_dir with extra files
# that may be not in e.g. .gitignore.
#
@dataclasses.dataclass
class SlotMeta:
    # Each time a dir is loaded from some slot (using "*" or by a concrete slot
    # id), we prepend slot id to this property.
    full_snapshot_history: list[str] = dataclasses.field(default_factory=list[str])

    def serialize(self) -> str:
        serialized = ""
        serialized += f"full_snapshot_history={' '.join(unique(self.full_snapshot_history)[0:MAX_FULL_SNAPSHOT_HISTORY])}\n"
        return serialized

    @staticmethod
    def deserialize(serialized: str) -> SlotMeta:
        self = SlotMeta()
        for line in serialized.splitlines():
            line = line.rstrip()
            match = re.match(r"^([^=]+)=(.*)$", line.rstrip())
            if match:
                key: str = match.group(1).strip()
                value: str = match.group(2).strip()
                if key == "full_snapshot_history":
                    self.full_snapshot_history = unique(value.split())
        return self

    def write_to(self, *, local_dir: str) -> None:
        with open(self._path(local_dir), "w") as f:
            f.write(self.serialize())

    @classmethod
    def read_from(cls, *, local_dir: str) -> SlotMeta:
        try:
            with open(cls._path(local_dir), "r") as f:
                return SlotMeta.deserialize(f.read())
        except FileNotFoundError:
            return SlotMeta()

    @staticmethod
    def _path(local_dir: str) -> str:
        return f"{LOCAL_META_FILE_DIR}/{META_FILE}.{normalize_slot_id(local_dir)}"


#
# An information returned from list_slots().
#
@dataclasses.dataclass
class SlotInfo:
    id: str
    age: int
    meta: SlotMeta


#
# Custom user exceptions.
#
class UserException(Exception):
    pass


#
# A reusable piece injected to SCRIPTS below. Returns all slot directories
# (including temporary, backup etc.) with their associated information. The
# newest slots appear on top of the list.
#
SLOT_INFOS = textwrap.dedent(
    r"""
    sub slot_infos {
        my ($storage_dir) = @_;
        return
            sort {
                $a->{age_sec} <=> $b->{age_sec}
                or
                $b->{slot_id} cmp $a->{slot_id}
            }
            map {
                my $dir = $_;
                $dir =~ s{/+$}{}s;
                my $inode_ctime = (stat($dir))[10];
                if ($inode_ctime) {
                    my $meta = "";
                    if (open(my $fh, "<", "$dir/%(META_FILE)s")) {
                        local $/ = undef;
                        $meta = <$fh>;
                        close($fh);
                    }
                    my $slot_id = $dir;
                    $slot_id =~ s{^.*/}{}s;
                    {
                        slot_id => $slot_id,
                        inode_ctime => $inode_ctime,
                        age_sec => time() - $inode_ctime,
                        dir => $dir,
                        meta => $meta,
                        is_garbage => $slot_id =~ /\./ ? 1 : 0,
                        is_bak => $slot_id =~ /\.bak\.\d+$/s ? 1 : 0,
                    };
                } else {
                    ();
                }
            }
            glob("$storage_dir/*/");
    }
    """.strip()
    % {"META_FILE": META_FILE}
)

#
# Inline scripts to run on the storage host. Reasons to use Perl:
# - It exists and is of the same version everywhere (as opposed to Python).
# - It is fast to boot and doesn't require external modules.
# - It has built-in flock() support.
# - If has native fork() support.
#
SCRIPTS = {
    # The script to list existing non-garbage slot ids, their ages in seconds
    # and meta content (where "\" has a traditional escaping meaning). Most
    # recent slots are on top of the list. It also pre-creates the storage
    # directory, and changes ctime of the most recent slot to the present time
    # (so it will unlikely be garbage collected soon).
    "LIST_SLOTS": textwrap.dedent(
        r"""
        use strict;
        my $storage_dir = $ARGV[0] or die("storage_dir argument required\n");
        length($storage_dir) >= 3 or die("storage_dir is suspiciously short\n");
        if (!-d $storage_dir) {
            system("mkdir", "-p", $storage_dir) == 0 or exit(1);
        }
        %(SLOT_INFOS)s
        my @slot_infos =
            grep { !$_->{is_garbage} }
            slot_infos($storage_dir);
        if (@slot_infos) {
            my $newest_dir = $slot_infos[0]{dir};
            my $newest_age_sec = $slot_infos[0]{age_sec};
            my $newest_inode_ctime = $slot_infos[0]{inode_ctime};
            utime(time(), time(), $newest_dir) or die("utime $newest_dir: $!\n");
            foreach (@slot_infos) {
                my $meta_encoded = $_->{meta};
                $meta_encoded =~ s/\\/\\\\/g;
                $meta_encoded =~ s/\r/\\r/g;
                $meta_encoded =~ s/\n/\\n/g;
                print("$_->{slot_id} $_->{age_sec} $meta_encoded\n");
            }
            print STDERR "returned ".scalar(@slot_infos)." slot(s) and also touched the newest slot $newest_dir (inode_ctime=$newest_inode_ctime, age_sec=$newest_age_sec)\n";
        }
        """.strip()
        % {"SLOT_INFOS": SLOT_INFOS}
    ),
    # The script to rename the new slot directory to the destination one.
    "COMMIT_SLOT": textwrap.dedent(
        r"""
        use strict;
        my $storage_dir = $ARGV[0] or die("storage_dir argument required\n");
        my $slot_id_tmp = $ARGV[1] or die("slot_id_tmp argument required\n");
        my $slot_id_dst = $ARGV[2] or die("slot_id_dst argument required\n");
        my $meta = $ARGV[3];
        length($storage_dir) >= 3 or die("storage_dir is suspiciously short\n");
        defined($meta) or die("meta argument required\n");
        my $slot_dir_tmp = "$storage_dir/$slot_id_tmp";
        my $slot_dir_dst = "$storage_dir/$slot_id_dst";
        my $slot_dir_bak = "$storage_dir/$slot_id_dst.bak." . time();
        my $META_FILE = "$slot_dir_tmp/%(META_FILE)s";
        -d $slot_dir_bak and (system("rm", "-rf", $slot_dir_bak) == 0 or die("rm -rf $slot_dir_bak: $!\n"));
        -d $slot_dir_dst and (system("mv", $slot_dir_dst, $slot_dir_bak) == 0 or die("mv $slot_dir_dst $slot_dir_bak: $!\n"));
        if ($meta) {
            open(my $fh, ">", $META_FILE) or die("open $META_FILE: $!\n");
            print($fh $meta) or die("write $META_FILE: $!\n");
            close($fh) or die("close $META_FILE: $!\n");
        } elsif (-f $META_FILE) {
            unlink($META_FILE) or die("unlink $META_FILE: $!\n");
        }
        system("mv", $slot_dir_tmp, $slot_dir_dst) == 0 or die("mv $slot_dir_tmp $slot_dir_dst: $!\n");
        print STDERR "renamed $slot_dir_tmp to $slot_dir_dst\n";
        utime(time(), time(), $slot_dir_dst) or die("utime $slot_dir_dst: $!\n");
        """.strip()
        % {"META_FILE": META_FILE},
    ),
    # This script is launched in background on the storage host to cleanup old or
    # broken slots.
    "MAINTENANCE": textwrap.dedent(
        r"""
        use strict;
        use POSIX "setsid";
        use IPC::Open3;
        *STDOUT->autoflush(1);
        *STDERR->autoflush(1);
        my $storage_dir = $ARGV[0] or die("storage_dir argument required\n");
        my $max_age_sec = $ARGV[1] or die("max_age_sec argument required\n");
        length($storage_dir) >= 3 or die("storage_dir is suspiciously short\n");
        my $lock_file = "$storage_dir/maintenance.lock";
        open(my $lock, ">>", $lock_file) or die("open $lock_file: $!\n");
        if (!flock($lock, 2 | 4)) { # LOCK_EX | LOCK_NB
            print("another maintenance process is already running, so skipping\n");
            exit(0);
        }
        %(SLOT_INFOS)s
        my @slot_infos = slot_infos($storage_dir);
        my $slot_dir_newest = (map { $_->{dir} } grep { !$_->{is_garbage} } @slot_infos)[0];
        my @rm_dirs = ();
        foreach my $info (@slot_infos) {
            my $dir = $info->{dir};
            my $age_sec = $info->{age_sec};
            my $is_bak = $info->{is_bak};
            if (defined($slot_dir_newest) && $dir eq $slot_dir_newest) {
                # Never delete the latest slot, even if it is old.
                next;
            }
            if ($age_sec > $max_age_sec || $is_bak && $age_sec > %(STORAGE_MAX_AGE_SEC_BAK)d) {
                push(@rm_dirs, $dir);
                print("will remove $dir (age: $age_sec sec) in background\n");
            }
        }
        if (!@rm_dirs) {
            unlink($lock_file);
            exit(0);
        }
        # https://linux.die.net/man/1/perlipc
        # We use open3, otherwise logger inherits our STDOUT/STDERR and doesn't let us close them.
        # To test logger in MacOS: log stream --info --predicate 'process == "logger"'
        open(my $devnull, ">", "/dev/null") or die("open /dev/null: $!\n");
        open(*STDIN, "<", "/dev/null") or die("open STDIN: $!\n");
        open3(*STDOUT, $devnull, $devnull, "logger", "-t", "ci-storage") or die("open3 STDOUT logger: $!\n");
        open(*STDERR, ">&", *STDOUT) or die("open STDERR: $!\n");
        *STDOUT->autoflush(1);
        *STDERR->autoflush(1);
        defined(my $pid = fork()) or die("fork: $!\n");
        $pid == 0 or exit(0);
        POSIX::setsid() != -1 or die("setsid: $!\n");
        foreach my $dir (@rm_dirs) {
            system("nice", "rm", "-rf", $dir) == 0 or die("rm -rf $dir: $!\n");
            print("removed $dir\n");
        }
        unlink($lock_file);
        """.strip()
        % {"SLOT_INFOS": SLOT_INFOS, "STORAGE_MAX_AGE_SEC_BAK": STORAGE_MAX_AGE_SEC_BAK}
    ),
}

#
# Script entry point.
#
if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(1)
    except UserException as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        print(
            textwrap.indent(
                f"Error: command returned status {e.returncode}."
                + (f"\n{e.stdout}" if e.stdout else "")
                + (f"\n{e.stderr}" if e.stderr else ""),
                "  ",
            ).rstrip(),
            file=sys.stderr,
        )
        sys.exit(2)
